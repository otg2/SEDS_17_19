{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "IMAGE_HEIGHT = 32\n",
    "IMAGE_WIDTH = 32\n",
    "IMAGE_CHANNELS = 3\n",
    "\n",
    "data_path = 'data/'\n",
    "\n",
    "\n",
    "# create some wrappers for simplicity\n",
    "def conv2d(x,W,b,strides=1):\n",
    "    # conv2d wrapper, with bias and relu activation\n",
    "    x = tf.nn.conv2d(x,W,strides=[1,strides,strides,1],padding='SAME')\n",
    "    # x = tf.nn.conv3d(x,W,strides=[1,strides,strides,strides,1],padding='SAME')\n",
    "    x = tf.nn.bias_add(x,b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "def maxpool2d(x,k=2):\n",
    "    # max2d wrapper\n",
    "    return tf.nn.max_pool(x,ksize=[1,k,k,1],strides=[1,k,k,1],padding='SAME')\n",
    "\n",
    "def conv_net(X,weights,biases,dropout):\n",
    "    X = tf.reshape(X, shape=[-1,IMAGE_HEIGHT,IMAGE_WIDTH,IMAGE_CHANNELS])\n",
    "\n",
    "    # convolustion layer\n",
    "    conv1 = conv2d(X,weights['wc1'],biases['bc1'])\n",
    "    # max pooling (down-sampling)\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "\n",
    "    # convolustion layer\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    # max pooling (down-sampling)\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "    \n",
    "    # apply dropout\n",
    "    # conv2 = tf.nn.dropout(conv2, 0.98)\n",
    "\n",
    "    # convolustion layer\n",
    "    conv3 = conv2d(conv2, weights['wc3'], biases['bc3'])\n",
    "    # max pooling (down-sampling)\n",
    "    conv3 = maxpool2d(conv3, k=2)\n",
    "    \n",
    "    # apply dropout\n",
    "    # conv3 = tf.nn.dropout(conv3, 0.95)\n",
    "\n",
    "    # convolustion layer\n",
    "    conv4 = conv2d(conv3, weights['wc4'], biases['bc4'])\n",
    "    # max pooling (down-sampling)\n",
    "    conv4 = maxpool2d(conv4, k=2)\n",
    "    \n",
    "    # apply dropout\n",
    "    # conv4 = tf.nn.dropout(conv4, 0.9)\n",
    "\n",
    "    # convolustion layer\n",
    "    conv5 = conv2d(conv4, weights['wc5'], biases['bc5'])\n",
    "    # max pooling (down-sampling)\n",
    "    conv5 = maxpool2d(conv5, k=2)\n",
    "    \n",
    "    # apply dropout\n",
    "    conv5 = tf.nn.dropout(conv5, 0.9)\n",
    "\n",
    "    # print(conv4.shape)\n",
    "    # fully connected layer\n",
    "    fc1 = tf.reshape(conv5, shape=[-1,weights['wd1'].get_shape().as_list()[0]])\n",
    "    # print('conv4 shape:', conv4.shape, ', fc1 shape:', fc1.shape)\n",
    "    fc1 = tf.add(tf.matmul(fc1,weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "\n",
    "    # apply dropout\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "\n",
    "    # output, class prediction\n",
    "    out = tf.add(tf.matmul(fc1,weights['out']), biases['out'])\n",
    "    return  out\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "lr_start = 0.001\n",
    "lr_end = 0.0001\n",
    "learning_rate = lr_start\n",
    "\n",
    "num_steps = 5000\n",
    "batch_size = 64\n",
    "update_step = 5\n",
    "display_step = 100\n",
    "train_acc_target = 1\n",
    "#train_acc_target_cnt = train_samples_size/batch_size\n",
    "# if train_acc_target_cnt>20:\n",
    "#     train_acc_target_cnt = 20\n",
    "\n",
    "# network parameters\n",
    "num_input = IMAGE_HEIGHT*IMAGE_WIDTH*IMAGE_CHANNELS\n",
    "num_classes = 10 # len(fruits_dict)\n",
    "dropout = 0.5\n",
    "\n",
    "# saver train parameters\n",
    "useCkpt = True\n",
    "checkpoint_step = 5\n",
    "checkpoint_dir = os.getcwd()+'\\\\checkpoint\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store layers weighta and bias\n",
    "weights = {\n",
    "    # 5x5 conv, 3 inputs, 16 outpus\n",
    "    'wc1': tf.get_variable('wc1',[3,3,3,32],initializer=tf.contrib.layers.xavier_initializer_conv2d()),\n",
    "    # 5x5 conv, 16 input, 32 outpus\n",
    "    'wc2': tf.get_variable('wc2',[3,3,32,64],initializer=tf.contrib.layers.xavier_initializer_conv2d()),\n",
    "    # 5x5 conv, 32 inputs, 64 outputs\n",
    "    'wc3': tf.get_variable('wc3',[3,3,64,128],initializer=tf.contrib.layers.xavier_initializer_conv2d()),\n",
    "    # 5x5 conv, 64 inputs, 128 outputs\n",
    "    'wc4': tf.get_variable('wc4',[3,3,128,256],initializer=tf.contrib.layers.xavier_initializer_conv2d()),\n",
    "    # 5x5 conv, 128 inputs, 256 outputs\n",
    "    'wc5': tf.get_variable('wc5', [3, 3, 256, 512], initializer=tf.contrib.layers.xavier_initializer_conv2d()),\n",
    "\n",
    "    # fully connected, 7*7*128 inputs, 2048 outputs\n",
    "    'wd1': tf.get_variable('wd1',[1*1*512,2048],initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    # 32 inputs, 26 outputs (class prediction)\n",
    "    'out': tf.get_variable('fc1',[2048,num_classes],initializer=tf.contrib.layers.xavier_initializer()),\n",
    "}\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.zeros([32])),\n",
    "    'bc2': tf.Variable(tf.zeros([64])),\n",
    "    'bc3': tf.Variable(tf.zeros([128])),\n",
    "    'bc4': tf.Variable(tf.zeros([256])),\n",
    "    'bc5': tf.Variable(tf.zeros([512])),\n",
    "    'bd1': tf.Variable(tf.zeros([2048])),\n",
    "    'out': tf.Variable(tf.zeros([num_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# tf graph input\n",
    "X = tf.placeholder(tf.float32,[None,num_input])\n",
    "Y = tf.placeholder(tf.float32,[None,num_classes])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# cconstruct model\n",
    "logits = conv_net(X,weights,biases,keep_prob)\n",
    "prediction = tf.nn.softmax(logits)\n",
    "\n",
    "\n",
    "correct_pred_index = tf.argmax(prediction,1)\n",
    "\n",
    "\n",
    "# initialization\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ottarg\\Documents\\SWED_NEURAL\\fruits\\checkpoint\\model.ckpt\n",
      "Checkpoint found  C:\\Users\\ottarg\\Documents\\SWED_NEURAL\\fruits\\checkpoint\\model.ckpt\n",
      "single image\n",
      "[1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:22: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nDone\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import misc\n",
    "\n",
    "\n",
    "# test accuracy\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    # create coord\n",
    "    coord2 = tf.train.Coordinator()\n",
    "    threads2 = tf.train.start_queue_runners(sess=sess, coord=coord2)\n",
    "\n",
    "    if useCkpt:\n",
    "        ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "        if ckpt and ckpt.model_checkpoint_path:\n",
    "            saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "            print(\"Checkpoint found \",str(ckpt.model_checkpoint_path))\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    if(True):\n",
    "        # Run 1 single image\n",
    "        print(\"single image\")\n",
    "        arr = misc.imread('avacado3.jpg') \n",
    "        imgShape = np.shape(arr)\n",
    "        if(imgShape[2] == 4):\n",
    "            arr = arr[:,:,:3]\n",
    "        arr = np.divide(arr,255) - 0.5\n",
    "        \n",
    "        imgToCheck = arr# test_images[index]\n",
    "        \n",
    "        labelArr = np.zeros(shape=[1, num_classes])\n",
    "        \n",
    "        imgToCheck = np.reshape(imgToCheck, [1, num_input])\n",
    "        np.set_printoptions(threshold=6)\n",
    "        testPrediction = sess.run(correct_pred_index, feed_dict={X: imgToCheck, Y: labelArr, keep_prob: 1})\n",
    "\n",
    "        print(testPrediction)\n",
    "    \n",
    "    # close coord\n",
    "    coord2.request_stop()\n",
    "    coord2.join(threads2)\n",
    "    sess.close()\n",
    "\"\"\"    \n",
    "0: 'Apple Red , \n",
    "1: 'Avocado', \n",
    "2: 'Banana', \n",
    "3: 'Kiwi', \n",
    "4: 'Lemon', \n",
    "5: 'Limes', \n",
    "6: 'Orange', \n",
    "7: 'Pear', \n",
    "8: 'Pineapple', \n",
    "9: 'Strawberry'\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "Done\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
